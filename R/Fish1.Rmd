---
title: "Fish_Stuff"
author: "Callie Stephenson"
date: "2024-03-28"
output: html_document
---

```{r}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)
```

```{r packages, message=FALSE}
library(dplyr)
library(readr)
library(here)
library(fishualize)
library(ggplot2)
library(vegan)
library(viridis)
library(tidyr)
library(stringr)
library(lme4)
library(mgcv)
library(gridExtra)
```


```{r data}
setwd("/Users/calliestephenson/Documents/GitHub/MooreaCoralFish_CS")
maxn <- read.csv("/Users/calliestephenson/Documents/GitHub/MooreaCoralFish_CS/data/MaxN.csv")
explan<- read.csv("data/explanatory_all_wide.csv") %>% 
  mutate(Pin = as.numeric(sub("V", "", CowTagID)))
```

### TIDY DATA:

First chunk of code subsets to only using 8 blocks per survey location, 4 from an 'on' and 4 from an 'adjacent'. I also remove pins where camera malfunctions made this not possible (Pin 13 and Pin 2).

```{r subset to 4 blocks per location}
block_count_per_location <- maxn %>%
  group_by(Pin, On.Adjacent) %>%
  summarise(num_blocks = n_distinct(Block))

set.seed(123)
subset_maxn <- maxn %>%
  filter(!(Pin == "13")) %>% 
  filter(!(Pin == "2")) %>% 
  group_by(Pin, On.Adjacent) %>%
  filter(Block %in% sample(unique(Block), 4, replace = FALSE)) %>%
  ungroup()

subset_block_count_per_location <- subset_maxn %>%
  group_by(Pin, On.Adjacent) %>%
  summarise(num_blocks = n_distinct(Block))

#Check that everybody has 4 blocks 2 times:
#table(subset_block_count_per_location$num_blocks, subset_block_count_per_location$Pin)
```

```{r if you want to see pin order of different explan}
# pin_order <- explan %>%
#   distinct(Pin, dist_to_seep_m) %>%
#   filter(Pin != 13) %>%  # Exclude Pin 13
#   arrange(dist_to_seep_m) %>%
#   pull(Pin)

pin_order <- explan %>%
  distinct(Pin, CV_pH) %>%
  filter(Pin != 13) %>%  # Exclude Pin 13
  arrange(CV_pH) %>%
  pull(Pin)
```

Removed unknowns, cryptic species, etc:
```{r}
subset_maxn_no_unk <- subset_maxn %>%
  filter(!str_detect(Species, "nknown")) %>% #anything that has nknown for unknown species
  filter(!(Species == "Bothus spp")) %>%  #goodbye flounder
  filter(!(Species == "Scorpaenopsis diabolus")) %>% #scorpoionfish are crpytic
  filter(!(Species == "Gymnothorax javanicus")) #sorry Julie
```

Since we could count some species as distinct individuals by life stages, I have combined those counts together here:

```{r combining life stages}
subset_maxn_combined_life_stages <- subset_maxn_no_unk %>%
  group_by(Pin, On.Adjacent, Block, Species) %>%
  summarise(MaxN = if(n_distinct(Juvenile.Adult) > 1) sum(MaxN) else max(MaxN), .groups = 'drop') %>%
  arrange(Pin, On.Adjacent, Block, Species)
```

And built a little code to double check that it went correctly (should create two empty data frames)
```{r checking this}
# Summarize to find duplicates
resolved_duplicates <- subset_maxn_combined_life_stages %>%
  dplyr::group_by(Pin, On.Adjacent, Block, Species) %>%
  dplyr::summarise(count = dplyr::n(), .groups = 'drop') %>%
  dplyr::filter(count > 1)

# Subset the original data to only include the duplicates
resolved_duplicate_rows <- subset_maxn_combined_life_stages %>%
  dplyr::inner_join(resolved_duplicates, by = c("Pin", "On.Adjacent", "Block", "Species")) %>%
  dplyr::arrange(Pin, On.Adjacent, Block, Species)
```

I then deal with extreme schooling events following methods from the Donovan regimes paper: "Additional methodology was developed for dealing with outliers in the fish data, accounting for extreme observations of schooling species. Extreme observations in the database were defined by calculating the upper 99.9% of all individual observations (e.g. one species, size and count on an individual transect), resulting in 26 observations out of over 0.5 million, comprised of 11 species. The distribution of individual counts in the entire database for those 11 species was then used to identify observations that fell above the 99.0% quantile of counts for each species individually. These observations were adjusted to the 99.0% quantile for analysis."

```{r}
# Identify extreme observations I am using the 99% quantile instead because my data is smaller
extreme_threshold <- quantile(subset_maxn_combined_life_stages$MaxN, probs = 0.99) 

# Identify species that have extreme observations
extreme_species <- subset_maxn_combined_life_stages %>%
  filter(MaxN > extreme_threshold) %>%
  pull(Species) %>%
  unique()

#make function to adjust counts for these species:
adjust_counts <- function(df, species, quantile_threshold) {
  quantile_value <- quantile(df$MaxN[df$Species == species], probs = quantile_threshold, na.rm = TRUE)
 df$MaxN[df$Species == species & df$MaxN > quantile_value] <- quantile_value
  return(df)
}

#make the adjustment. I'm adjusting to the 90% quantile
for (sp in extreme_species) {
  adjusted_subset_maxn <- adjust_counts(subset_maxn_combined_life_stages, sp, 0.90)
}
```

I want to make sure blocks are summarized appropriately, so I renamed them:
```{r}
adjusted_subset_maxn$Block <- paste0(adjusted_subset_maxn$On.Adjacent, " ", adjusted_subset_maxn$Block) #I want to make sure that factor levels are different for each combo of on/adjacent and block so that I don't accidentially combine blocks 
```

and ending by renaming the dataframe as just fish_tidy for future use:
this allows me to make extra tidy data adjustments without breaking the dataframe name later on in the code!
```{r make fish tidy}
fish_tidy <- adjusted_subset_maxn
```

## Resource Fish Only

I'm pulling a list of fished genus from the paper "Perceptions and responses of Pacific Island fishers to changing coral reefs" by Rassweiler et al., 2021. I am editing fish_tidy to split genus and species, creating a column based off whether the genus is on the list for Rassweiler et al, and then making that into a binary variable 'Resource'.

Also in this paper, it shows that "Naso, Chlorurus and Scarus collectively composed the bulk of the fishable biomass on the reef (48–66%) and a roughly similar total proportion of the catch (43–65%)." I have made a variable 'most_targeted' for these genus.

```{r}
rassweiler_resource <- c("Chlorurus", "Scarus", "Naso", "Myripristis", "Siganus", "Mulloidichthys", "Parupeneus", "Epinephelus", "Selar", "Cypselurus", "Acanthurus", "Cephalopholis", "Cheilopogon", "Sargocentron", "Lutjanus", "Monotaxis", "Caranx", "Lethrinus", "Calotomus", "Heteropriacanthus", "Cheilinus", "Gnathodentex", "Kyphosus")

most_targeted <- c("Chlorurus", "Scarus", "Naso")

fish_tidy_resource <- fish_tidy %>%
  separate(Species, into = c("Genus", "sp"), sep = " ",remove = FALSE) %>% 
  mutate(Resource = if_else(Genus %in% rassweiler_resource, 1, 0))%>% 
  mutate(Most_targeted = if_else(Genus %in% most_targeted, 1, 0)) %>% 
  select(-Genus, -sp)
```

## Wide data for ordination:
I've also made a wide version of the data frame for ordination:

```{r wide data}
#make it wide
wide_maxn_df <- pivot_wider(fish_tidy, 
                             id_cols = c("Pin", "Block"),
                             names_from = Species, 
                             values_from = MaxN)

#make the NAs as 0's
wide_maxn_df <- wide_maxn_df %>% 
  mutate_all(~ifelse(is.na(.), 0, .))
```

Then used that one to re-make the long data frame with a presence column instead of abundance
```{r long data with presence}
species <- names(wide_maxn_df[,c(3:ncol(wide_maxn_df))])

fish_long <- pivot_longer(wide_maxn_df,
                          cols = species,
                          names_to = "species",
                          values_to = "Abundance")
#This is going to be much longer, because it has a row for every species at every block

#check it:
# original_combinations <- fish_tidy %>% select(Pin, Block) %>% distinct()
# transformed_combinations <- fish_long %>% select(Pin, Block) %>% distinct()
# 
# all.equal(original_combinations, transformed_combinations)

presence <- fish_long %>% 
  mutate(Presence = ifelse(Abundance == 0, 0, 1))

#and making a column for resource and most targeted fish (which is done at the genus level)
presence_resource <- presence %>%
  separate(species, into = c("Genus", "sp"), sep = " ",remove = FALSE) %>% 
  mutate(Resource = if_else(Genus %in% rassweiler_resource, 1, 0))%>% 
  mutate(Most_targeted = if_else(Genus %in% most_targeted, 1, 0)) %>% 
  select(-Genus, -sp)
```


# Data Vis

Linda from Johanssen Lab reccommended to make a plot that is ordered by the most abundant fish near the seep and look for any patterns, so I went and made this plot a number of ways. First, I kept all the species and looked a just the average abundance at all pins, to see if the communities looked relatively similar in this way.

#### All species average abundance across gradient
```{r average maxn at each pin, fig.height= 10, fig.width=6}
maxn_avg <- fish_tidy %>%
  group_by(Pin, Species) %>%
  summarize(avg_MaxN = sum(MaxN, na.rm = TRUE) / 8)

maxn_avg %>%
  ggplot(aes(x = Species, y = avg_MaxN)) +
  geom_bar(stat = "identity", position = "dodge") +
  facet_wrap(~ Pin) +
  labs(y = "Average MaxN", x = "Block", title = "Average MaxN of Each Species Across Blocks by Pin") +
  coord_flip()+
  theme_minimal()
```

This is too busy to read, and no major patterns jump out. I subset this to just the top 20 species along the gradient, and again the order of the pins does not have biological relevance.

#### Most common 20 species average abundance across gradient
```{r same but only top 20 species, fig.height= 10, fig.width=6}
# Step 1: Calculate the overall average MaxN for each species
species_avg <- maxn_avg %>%
  group_by(Species) %>%
  summarize(overall_avg_MaxN = mean(avg_MaxN, na.rm = TRUE)) %>%
  arrange(desc(overall_avg_MaxN))

# Step 2: Identify the top 20 species based on the overall average MaxN
top_species <- species_avg %>%
  top_n(20, overall_avg_MaxN) %>%
  pull(Species)

maxn_avg_top <- maxn_avg %>%
  filter(Species %in% top_species)

maxn_avg_top %>%
  ggplot(aes(x = Species, y = avg_MaxN)) +
  geom_bar(stat = "identity", position = "dodge") +
  facet_wrap(~ Pin) +
  labs(y = "Average MaxN", x = "Block", title = "Average MaxN of Each Species Across Blocks by Pin") +
  coord_flip()+
  theme_minimal()
```

#### So, now I will order the pins by those most common at pin 14

```{r pin 14 most common, fig.height= 10, fig.width=6}
# Step 1: Create a new column for avg_MaxN at Pin 14
pin14_avg <- maxn_avg_top %>%
  filter(Pin == 14) %>%
  dplyr::select(Species, avg_MaxN) %>%
  rename(MaxN_Pin14 = avg_MaxN)

# Step 2: Add MaxN_Pin14 to the original dataframe and calculate overall average MaxN
maxn_avg_top <- maxn_avg_top %>%
  left_join(pin14_avg[,c("Species","MaxN_Pin14")], by = "Species") %>%
  group_by(Species) %>%
  mutate(overall_avg_MaxN = mean(avg_MaxN, na.rm = TRUE)) %>%
  ungroup()

# Step 3: Define species order based on MaxN_Pin14 and overall_avg_MaxN
species_order <- maxn_avg_top %>%
  # Replace NA in MaxN_Pin14 with a very low value to ensure they come last
  mutate(MaxN_Pin14 = ifelse(is.na(MaxN_Pin14), -Inf, MaxN_Pin14)) %>%
  arrange(desc(MaxN_Pin14), desc(overall_avg_MaxN)) %>%
  pull(Species) %>%
  unique()

# Step 4: Reorder species factor levels
maxn_avg_top <- maxn_avg_top %>%
  mutate(Species = factor(Species, levels = species_order))

# Step 5: Create the plot with the reordered species
p1 <- maxn_avg_top %>%
  ggplot(aes(x = Species, y = avg_MaxN)) +
  geom_bar(stat = "identity", position = "dodge") +
  facet_wrap(~ Pin) +
  labs(y = "Average MaxN", x = "Species", title = "Average Abundance of the Most Common 20 Species Across Sampling Locations") +
  coord_flip() +  # Flip coordinates to have species names on y-axis
  theme_linedraw()+ 
  theme(plot.title = element_text(size=9))

p1

#ggsave(filename = "output/most_common_fish.png", p1, height = 10, width = 5)
```

This isn't showing the most obvious patterns, but there were only a few species of fish that swam in the sand near the seep. So, I'll reorder the pins by the distance to the seep

#### Most common species average abundance at each pin by distance to seep:

```{r by dist to seep, fig.height= 10, fig.width=6}
maxn_explan <- left_join(maxn_avg_top, explan[,c("Pin", "dist_to_seep_m", "Low_Tide_Mean_Silicate_umolL", "sd_Salinity")])

pin_order <- maxn_explan %>%
  distinct(Pin, dist_to_seep_m) %>%
  filter(Pin != 13) %>%  # Exclude Pin 13
  arrange(dist_to_seep_m) %>%
  pull(Pin)

maxn_explan <- maxn_explan %>%
  mutate(Pin = factor(Pin, levels = pin_order)) 

maxn_explan %>%
  ggplot(aes(x = Species, y = avg_MaxN)) +
  geom_bar(stat = "identity", position = "dodge") +
  facet_wrap(~ Pin) +
  labs(y = "Average MaxN", x = "Species", title = "Average Abundance of Each Species at Sampling Locations") +
  coord_flip()+
  theme_minimal()
```

To see if maybe a nutrient parameter would be good descriptor, I do this also by the low tide mean silicate

#### Most common species average abundance across the gradient of low tide mean silicate

```{r by dist to silicate, fig.height= 10, fig.width=6}
explan <- explan %>%
  mutate(Pin = as.numeric(sub("V", "", CowTagID)))

maxn_explan <- left_join(maxn_avg_top, explan[,c("Pin", "dist_to_seep_m", "Low_Tide_Mean_Silicate_umolL")])

pin_order <- maxn_explan %>%
  distinct(Pin, Low_Tide_Mean_Silicate_umolL) %>%
#  filter(Pin != 13) %>%  # Exclude Pin 13
  arrange(Low_Tide_Mean_Silicate_umolL) %>%
  pull(Pin)

maxn_explan <- maxn_explan %>%
  mutate(Pin = factor(Pin, levels = pin_order)) 

maxn_explan %>%
  ggplot(aes(x = Species, y = avg_MaxN)) +
  geom_bar(stat = "identity", position = "dodge") +
  facet_wrap(~ Pin) +
  labs(y = "Average MaxN", x = "Species", title = "Average Abundance of Each Species at Sampling Locations") +
  coord_flip()+
  theme_minimal()
```

#### Most common species average abundance across the gradient of nutrient delivery
Nutrient delivery quantified as a pc axis I got from the low tide mean of major nutrients across the gradient.This axis captures 72.87298% of the variation in mean low tide TA, Phosphate, Silicate, and N + N. Higer numbers on this axis indicate higher values of these variables.

```{r by pulse pc 1, fig.height= 10, fig.width=6}
explan <- explan %>%
  mutate(Pin = as.numeric(sub("V", "", CowTagID)))

maxn_explan <- left_join(maxn_avg_top, explan[,c("Pin", "pulse_pc1", "Low_Tide_Mean_Silicate_umolL")])

pin_order <- maxn_explan %>%
  distinct(Pin, pulse_pc1) %>%
#  filter(Pin != 13) %>%  # Exclude Pin 13
  arrange(pulse_pc1) %>%
  pull(Pin)

maxn_explan <- maxn_explan %>%
  mutate(Pin = factor(Pin, levels = pin_order)) 

maxn_explan %>%
  ggplot(aes(x = Species, y = avg_MaxN)) +
  geom_bar(stat = "identity", position = "dodge") +
  facet_wrap(~ Pin) +
  labs(y = "Average MaxN", x = "Species", title = "Average Abundance of Each Species at Sampling Locations") +
  coord_flip()+
  theme_minimal()
```

## Alpha Diversity:

#### Calculating richness against gradient metrics:

```{r}
species_richness <- fish_tidy %>%
  filter(!Pin == "13") %>% 
  filter(!Pin == "14") %>% 
  group_by(Pin, On.Adjacent, Block) %>%
  summarise(Richness = n_distinct(Species[MaxN > 0]))

species_richness_explan <- left_join(species_richness, explan[,c("Pin", "pulse_pc1", "Low_Tide_Mean_Silicate_umolL","dist_to_seep_m")])

p1 <- species_richness_explan %>%
  ggplot(aes(x = Low_Tide_Mean_Silicate_umolL, y = Richness)) +
#  geom_text(aes(label = Pin))+
  geom_point() +
  geom_smooth() +
  theme_minimal() +
  facet_wrap(~On.Adjacent)

p2 <- species_richness_explan %>%
  ggplot(aes(x = pulse_pc1, y = Richness)) +
#  geom_text(aes(label = Pin))+
  geom_point() +
  geom_smooth() +
  theme_minimal()+
  facet_wrap(~On.Adjacent)

p3 <- species_richness_explan %>%
  ggplot(aes(x = dist_to_seep_m, y = Richness)) +
#  geom_text(aes(label = Pin))+
  geom_point() +
  geom_smooth() +
  theme_minimal()+
  facet_wrap(~On.Adjacent)

grid.arrange(p1, p2, p3, nrow = 1)
```

#### Calculating diversity against gradient metrics:
```{r}
species_diversity <- fish_tidy %>%
  filter(!Pin == "13") %>% 
  filter(!Pin == "14") %>% 
  group_by(Pin, On.Adjacent, Block) %>%
  summarise(Diversity = diversity(MaxN, index = "shannon"))

species_diversity_explan <- left_join(species_diversity, explan[,c("Pin", "pulse_pc1", "Low_Tide_Mean_Silicate_umolL","dist_to_seep_m")])

p1 <- species_diversity_explan %>%
  ggplot(aes(x = Low_Tide_Mean_Silicate_umolL, y = Diversity)) +
#  geom_text(aes(label = Pin))+
  geom_point() +
  geom_smooth() +
  theme_minimal()+
  facet_wrap(~On.Adjacent)

p2 <- species_diversity_explan %>%
  ggplot(aes(x = pulse_pc1, y = Diversity)) +
#  geom_text(aes(label = Pin))+
  geom_point() +
  geom_smooth() +
  theme_minimal()+
  facet_wrap(~On.Adjacent)

p3 <- species_diversity_explan %>%
  ggplot(aes(x = dist_to_seep_m, y = Diversity)) +
#  geom_text(aes(label = Pin))+
  geom_point() +
  geom_smooth() +
  theme_minimal() +
  facet_wrap(~On.Adjacent)

grid.arrange(p1, p2, p3, nrow = 1)
```

## NMDS Non-Dimensional Ordination
Code from Linda:

```{r species data use}
##make a dataframe with ONLY your fish data
##within the parentheses you write which columns this would be
Fish2 <-wide_maxn_df[c(3:ncol(wide_maxn_df))]

##extract the info about location (in this case your habitats) from the dataset, this table needs to have equal number of rows as the fish table
Sites<-wide_maxn_df[c(1)]
#str(Sites)
```


I've been going back and forth on the transformation here, and am currently going with hellinger instead of vegan's default, the wisconsin. This is because, from my limited understanding, the hellinger better handles cases where species are not present in multiple sites (known as double zeros). 

```{r transform}
##hellinger transformation is a common transformation with community data when you have a lot of zeros
Fish_com <- decostand(Fish2, method = "hellinger" )

##constructing the dissimilarity matrix, using bray -curtis "how differently are they different"
mat.dis_fish <- vegdist(Fish_com,method="bray")
```

```{r}
set.seed(123)

nmds = metaMDS(mat.dis_fish,k=2, trymax=500, distance = "bray")
##stressplot is just a diagnostic for your data, shows how your datapoints are distributed and should be somewhat linear..
stressplot(nmds) 
nmds

##Stress Value = how well doe your NMDS represent reality (<0.2)
plot(nmds, type = "text")
plot(nmds)
```

```{r}
data.scores = as.data.frame(scores(nmds))
#including the factors 

data.scores$Site = Sites$Pin
#data.scores$Site <- factor(data.scores$Site, levels = c(1:223))

head(data.scores)
```

```{r}
data.spp.fit <- envfit(nmds, Fish2, permutations = 999)

head(data.spp.fit)

spp.scrs <- as.data.frame(scores(data.spp.fit, display = "vectors")) #save species intrinsic values into dataframe
spp.scrs <- cbind(spp.scrs, Species = rownames(spp.scrs)) #add species names to dataframe

#head(spp.scrs)
# Extract p-values from the envfit result
pvals <- data.spp.fit$vectors$pvals
# Add the p-values to the spp.scrs dataframe
spp.scrs$pval <- pvals

# Subset data to show species significant at 0.05
sig.spp.scrs <- subset(spp.scrs, pval <= 0.05)

# sig.spp.scrs <- spp.scrs
# sig.spp.scrs <- subset(spp.scrs, pvals<=0.05) #subset data to show species significant at 0.05

head(sig.spp.scrs)
```

```{r}
##set theme!
mytheme3<-theme(axis.title = element_text(size = 12, colour = "black"), 
                panel.background = element_blank(), panel.border = element_rect(fill = NA, colour = "black"), 
                axis.ticks = element_blank(), axis.text = element_text(size = 12), legend.key = element_blank(), 
                legend.title = element_text(size = 12, colour = "black"), 
                legend.text = element_text(size = 12, colour = "black"))
```

```{r}
library(viridis)
gg2 <- ggplot(data = data.scores, aes(x = NMDS1, y = NMDS2))+ 
  scale_color_viridis(discrete = TRUE, option = "D")+
  scale_fill_viridis(discrete = TRUE)+
  labs(colour = "Site")+
 ggtitle("NMDS")+  mytheme3

data.scores$Site <- as.factor(data.scores$Site)

g2<-gg2+geom_point(data = data.scores, aes(colour = Site, shape = Site),size = 3, alpha = 0.8)+
  #geom_segment(aes(x = 0, y = 0, xend = NMDS1, yend = NMDS2), 
             #  data = spp.scrs)+
  ggrepel::geom_text_repel(data = sig.spp.scrs, aes(x=NMDS1, y=NMDS2, label = Species), cex = 3, direction = "both", segment.size = 0.25) #add labels for species, use ggrepel::geom_text_repel so that labels do not overlap

g2 <- g2 + scale_shape_manual(values = 1:20)  # Assuming there are 20 unique sites

g2
```

```{r FOR MACKENZIE!!!}
g3 <- gg2+geom_point(data = data.scores, aes(colour = Site, shape = Site),size = 3, alpha = 0.8)+ scale_shape_manual(values = 1:20)
g3

#ggsave("NMDS_for_MT.png", g3)
```

```{r}
gg1 =ggplot(data = data.scores, aes(x = NMDS1, y = NMDS2))+ 
  scale_color_viridis(discrete = TRUE, option = "D")+
  scale_fill_viridis(discrete = TRUE)+
  labs(colour = "Reef.zone")+
  stat_ellipse(aes(fill = Site), geom = "polygon", alpha = .4,
               type="t",level = 0.95,linetype = 3)+ ggtitle("My NMDS")+  mytheme3


g1<- gg1+
  geom_point(data = data.scores, aes(shape = Site),size = 3, alpha = 0.8)+
  geom_segment(aes(x = 0, y = 0, xend = NMDS1, yend = NMDS2), 
               data = spp.scrs, size =0.5, alpha = 0.8, colour = "grey30")+
  scale_shape_manual(values = 1:20)+
  ggrepel::geom_text_repel(data = spp.scrs, aes(x=NMDS1, y=NMDS2, label = Species), cex = 3, direction = "both", segment.size = 0.25) #add labels for species, use ggrepel::geom_text_repel so that labels do not overlap

g1
```

```{r add species names in the data}
spp.scrs3 <- as.data.frame(scores(data.spp.fit, display = "vectors")) #save species intrinsic values into dataframe
spp.scrs3 <- cbind(spp.scrs3, Species = rownames(spp.scrs3)) #add species names to dataframe
spp.scrs3 <- cbind(spp.scrs3, pval = data.spp.fit$vectors$pvals) #add pvalues to dataframe so you can select species which are significant

#spp.scrs<- cbind(spp.scrs, abrev = abbreviate(spp.scrs$Species, minlength = 6)) #abbreviate species names
sig.spp.scrs3 <- subset(spp.scrs3, pval<=0.008) #subset data to show species significant at 0.05

sig.spp.scrs3
```
```{r set theme}
##set theme!
mytheme3<-theme(axis.title = element_text(size = 12, colour = "black"), 
                panel.background = element_blank(), panel.border = element_rect(fill = NA, colour = "black"), 
                axis.ticks = element_blank(), axis.text = element_text(size = 12), legend.key = element_blank(), 
                legend.title = element_text(size = 12, colour = "black"), 
                legend.text = element_text(size = 12, colour = "black"))
```

```{r add species names in the data to the plot}
options(ggrepel.max.overlaps = Inf)

gg2 = ggplot(data = data.scores, aes(x = NMDS1, y = NMDS2))+
  scale_color_viridis(discrete = TRUE, option = "D")+
  scale_fill_viridis(discrete = TRUE)+
  labs(colour = "Location")+
  stat_ellipse(aes(fill = Site), geom = "polygon", alpha = .15,
               type="t",level = 0.95,linetype = 3)+
  scale_shape_manual(values = 1:20)+
  mytheme3

g2<-gg2+geom_point(data = data.scores, aes(colour = Site, shape = Site),size = 3, alpha = 0.7)+
  geom_segment(aes(x = 0, y = 0, xend = NMDS1, yend = NMDS2),
               data = sig.spp.scrs3, size =0.5, alpha = 0.5, colour = "grey30")+
  ggrepel::geom_text_repel(data = sig.spp.scrs3, aes(x=NMDS1, y=NMDS2, label = Species), cex = 3, direction = "both", segment.size = 0.5, max.overlaps = 15) #add labels for species, use ggrepel::geom_text_repel so that labels do not overlap
g2

#ggsave("NMDS_sig_spp.png", g2, width=15, height=10)
```

```{r, fig.width=20, fig.height=20}
options(ggrepel.max.overlaps = Inf)

gg2 = ggplot(data = data.scores, aes(x = NMDS1, y = NMDS2))+
  scale_color_viridis(discrete = TRUE, option = "D")+
  scale_fill_viridis(discrete = TRUE)+
  labs(colour = "Location")+
  stat_ellipse(aes(fill = Site), geom = "polygon", alpha = .15,
               type="t",level = 0.95,linetype = 3)+
  scale_shape_manual(values = 1:20)+
  mytheme3

g2<-gg2+geom_point(data = data.scores, aes(colour = Site, shape = Site),size = 3, alpha = 0.7)+
  geom_segment(aes(x = 0, y = 0, xend = NMDS1, yend = NMDS2),
               data = sig.spp.scrs3, size =0.5, alpha = 0.5, colour = "grey30")+
  geom_text(data = sig.spp.scrs3, aes(x=NMDS1, y=NMDS2, label = Species), cex = 3, direction = "both", segment.size = 0.5, max.overlaps = 15) #add labels for species, use ggrepel::geom_text_repel so that labels do not overlap
g2

#ggsave("NMDS_with_sig_spp.png", g2, width = 20, height = 20)
```



# Constrained Ordination - Distance based redundancy analysis

I started with using the pulse pc axis, the low tide mean silicate, the distance to seep, and the distance to shore:

Tests revealed the shore distance didn't matter (permutation test p = 0.555), so I changed this to only use the pulse pc axis, the low tide mean silicate, the distance to seep, and the distance to shore:
```{r Distance based redundancy analysis}
# ##hellinger transformation is a common transformation with community data when you have a lot of zeros
Species_only <-wide_maxn_df[c(3:ncol(wide_maxn_df))]
transformed_communities <- decostand(Species_only, method = "hellinger" )

# Extract the 'Pin' column from wide_maxn_df to merge with transformed data
Pin_column <- wide_maxn_df["Pin"]

# Combine the Pin column with the transformed species data
transformed_communities_with_pin <- cbind(Pin_column, transformed_communities)
transformed_communities_with_explan <- left_join(transformed_communities_with_pin, explan[,c("Pin", "Low_Tide_Mean_Phosphate_umolL", "Low_Tide_Mean_Silicate_umolL", "dist_to_seep_m", "Low_Tide_Mean_NN_umolL","Low_Tide_Mean_Ammonia_umolL")], by = join_by(Pin))
cap = capscale(transformed_communities ~ Low_Tide_Mean_Phosphate_umolL + Low_Tide_Mean_Silicate_umolL + dist_to_seep_m + Low_Tide_Mean_NN_umolL + Low_Tide_Mean_Ammonia_umolL, data = transformed_communities_with_explan, dist = "bray")
cap
```

The output reports the total inertia, which is the total amount of variation (dissimilarity) in the data. This inertia is decomposed into ‘constrained’ and ‘unconstrained’ components. The constrained component is the total amount of variation explained by the predictors (18.36%), while the unconstrained component is the remaining ‘residual’ variation. There is also info on ‘real’ and ‘imaginary’ components, due to the negative eigenvalues issue which arises with PCoA.


The default plot shows how these variables are loaded onto the first two CAP axes, and shows how the samples (circles) are ordinated on those axes, as well as the species scores (red crosses).
```{r}
plot(cap)
```

We can get the variance explained by these axes from summary:
```{r}
summary(cap)$cont
```

The first CAP axis explains 6.97% of the constrained community variation, and the second axis explains 4.34%. Therefore, this represents 2.07% of the total community variation. 

Though this is already pretty poor, I might as well finish it out as a coding exercise. The loading coefficients for the explanatory variables on the constrained axes are: 

```{r}
summary(cap)$biplot
```

To test the important of all the predictors in combination:
```{r}
anova(cap)
```

So this tests whether the total variation explained by the constrained axes is significant. Interestingly, though the amount of variation seems trivial, it is showing up as significant...

```{r}
anova(cap, by = "axis")
```
So, both the axes we have plotted are considered significant.

```{r}
anova(cap, by = "margin")
```

Interestingly, all the axes are coming up as significant contributors to this variation.

# PERMANOVA:
```{r}
PERMANOVA = adonis2(transformed_communities ~ Low_Tide_Mean_Phosphate_umolL + Low_Tide_Mean_Silicate_umolL + dist_to_seep_m + Low_Tide_Mean_NN_umolL + Low_Tide_Mean_Ammonia_umolL, data = transformed_communities_with_explan, dist = "bray", by = 'margin')

PERMANOVA
```

Again, all of our variables are significant contributors to community composition, though with very low r2.

# Mixed Models for Multivariate Data

The first model I test is looking at the probability of presence, and whether it differs between the CV of Salinity. With this, the effect of salinity differs randomly around the species. The random effect for salinity can quantify how much the community composition chnanges along the gradient. If the random effect is non-0, the species change in relative abundance along the salinity gradient.
```{r}
# mod.season = glmer(presence ~ season + (1+season|species), data = channel, family = binomial)
# mod.no.season = glmer(presence ~ season + (1|species), data = channel, family= binomial)
# anova(mod.season, mod.no.season)

presence_explan <- left_join(presence, explan[,c("Pin", "CV_Salinity")],by = join_by(Pin))

mod.salinity = glmer(Presence ~ CV_Salinity + (1+CV_Salinity|species), data = presence_explan, family = binomial)

summary(mod.salinity)
dotplot(ranef(mod.salinity, condVar = T))
```

We can test the salinity effect by dropping the random slope and doing an LRT
```{r}
mod.no.salinity = glmer(Presence ~ CV_Salinity + (1|species), data = presence_explan, family= binomial)
anova(mod.salinity, mod.no.salinity)
```

This doesn't look great, but the technique is interesting.

# GAM

I want to try to do this to look at non-linear distribution along the gradient. I think some species might be non-linear as they might avoid the highly fresh region. I think this might be easiest to look at if I only looked at certain species of interest, which I still would like to define.

For now, I'm setting up the code using species driving differences in the nmds

```{r gam tidy}
gam_species <- sig.spp.scrs$Species

gam_fish <- presence %>% 
  filter(species %in% gam_species) %>% 
  left_join(explan[,c("Pin", "dist_to_seep_m")],by = join_by(Pin))

gam_fish$species <- as.factor(gam_fish$species)

#for just resource
resource_gam <- presence_resource %>% 
#  filter(species %in% gam_species) %>% 
  filter(Resource != 0) %>% #remove non-resource species
  left_join(explan[,c("Pin", "dist_to_seep_m")],by = join_by(Pin))

resource_gam$species <- as.factor(resource_gam$species)
```


```{r}
gam.sig.fish <- gam(Presence ~ s(CV_Salinity) + s(species, bs = "re"),
                    data = gam_fish,
                    family = binomial(link = "logit"))

summary(gam.sig.fish)

mgcv::plot.gam(gam.sig.fish)

gam.sig.fish = gam(Presence ~ s(dist_to_seep_m, by = species), data = gam_fish, family = binomial)

summary(gam.sig.fish)

par(mar = c(1, 1, 2, 1)) 
mgcv::plot.gam(gam.sig.fish, pages = 10)

```

```{r}
res.gam.sig.fish = gam(Presence ~ s(dist_to_seep_m, by = species), data = resource_gam, family = binomial)

summary(res.gam.sig.fish)

par(mar = c(1, 1, 2, 1)) 
mgcv::plot.gam(res.gam.sig.fish, pages = 10)
```
  
This code didn't really work as intended. But, when I talked to Kyle Edwards, he suggested that I make a different gam for each species. This is more or less a preliminary step to see if a linear fit is good enough for this data:


```{r presence different gam for each species}
# Create an empty list to store the models and plots
models <- list()
plots <- list()

# Loop over each unique species
for(spec in unique(resource_gam$species)) {
  # Subset the data for the current species
  species_data <- subset(resource_gam, species == spec)
  
  # Fit the GAM for the current species
  gam_model <- gam(Presence ~ s(dist_to_seep_m), data = species_data, family = binomial)
  
  # Store the model in the list
  models[[spec]] <- gam_model
  
  # Create a data frame for predictions
  pred_data <- data.frame(
    dist_to_seep_m = seq(min(species_data$dist_to_seep_m), max(species_data$dist_to_seep_m), length.out = 100)
  )
  
  # Predict the presence probability
  pred_data$Presence <- predict(gam_model, newdata = pred_data, type = "response")
  
  # Plot the results
  p <- ggplot(data = pred_data, aes(x = dist_to_seep_m, y = Presence)) +
    geom_line() +
    labs(title = paste(spec)) +
    theme_minimal()+
  theme(plot.title = element_text(face = "italic"))
  
  # Store the plot in the list
  plots[[spec]] <- p
}

# Arrange all plots together in a grid
do.call(grid.arrange, c(plots, ncol = 4))
```

```{r different ABUNDANCE gam for each resource species}
# Create an empty list to store the models and plots
models <- list()
plots <- list()

# Loop over each unique species
for(spec in unique(resource_gam$species)) {
  # Subset the data for the current species
  species_data <- subset(resource_gam, species == spec)
  
  # Fit the GAM for the current species
  gam_model <- gam(Abundance ~ s(dist_to_seep_m), data = species_data, family = nb(), 
                 control = gam.control(maxit = 100, epsilon = 1e-6))
  
  # Store the model in the list
  models[[spec]] <- gam_model
  
  # Create a data frame for predictions
  pred_data <- data.frame(
    dist_to_seep_m = seq(min(species_data$dist_to_seep_m), max(species_data$dist_to_seep_m), length.out = 100)
  )
  
  # Predict the abundance
  pred_data$Abundance <- predict(gam_model, newdata = pred_data, type = "response")
  
  # Plot the results
  p <- ggplot(data = pred_data, aes(x = dist_to_seep_m, y = Abundance)) +
    geom_line() +
    labs(x = "Distance to Seep", title = paste(spec))  +
    theme_minimal() +
    theme(plot.title = element_text(size = 10))
  
  # Store the plot in the list
  plots[[spec]] <- p
}

# Arrange all plots together in a grid
individual_abundance_gam <- do.call(grid.arrange, c(plots, ncol = 5))

#ggsave(filename = "output/abundance_gam_resoure_fish.png", individual_abundance_gam, height = 10, width = 10)
```

From further inspection, the model has issues with Naso annulatus, Naso unicornis, Scarus oviceps

print(warnings_list[["Naso unicornis"]])
[1] "Iteration limit reached without full convergence - check carefully"

print(warnings_list[["Naso annulatus"]])
[1] "Fitting terminated with step failure - check results carefully"

print(warnings_list[["Scarus oviceps"]])
[1] "Fitting terminated with step failure - check results carefully"

```{r presence different gam for each species}
# Create an empty list to store the models and plots
models <- list()
plots <- list()

# Loop over each unique species
for(spec in unique(gam_fish$species)) {
  # Subset the data for the current species
  species_data <- subset(gam_fish, species == spec)
  
  # Fit the GAM for the current species
  gam_model <- gam(Presence ~ s(dist_to_seep_m), data = species_data, family = binomial)
  
  # Store the model in the list
  models[[spec]] <- gam_model
  
  # Create a data frame for predictions
  pred_data <- data.frame(
    dist_to_seep_m = seq(min(species_data$dist_to_seep_m), max(species_data$dist_to_seep_m), length.out = 100)
  )
  
  # Predict the presence probability
  pred_data$Presence <- predict(gam_model, newdata = pred_data, type = "response")
  
  # Plot the results
  p <- ggplot(data = pred_data, aes(x = dist_to_seep_m, y = Presence)) +
    geom_line() +
    labs(title = paste(spec)) +
    theme_minimal()+
  theme(plot.title = element_text(face = "italic"))
  
  # Store the plot in the list
  plots[[spec]] <- p
}

# Arrange all plots together in a grid
do.call(grid.arrange, c(plots, ncol = 4))
```