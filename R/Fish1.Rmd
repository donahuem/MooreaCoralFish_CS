---
title: "Fish_Stuff"
author: "Callie Stephenson"
date: "2024-03-28"
output: html_document
---

```{r}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)
```

```{r packages, message=FALSE}
library(dplyr)
library(readr)
library(here)
library(fishualize)
library(ggplot2)
library(vegan)
library(viridis)
library(tidyr)
```


```{r data}
setwd("/Users/calliestephenson/Documents/GitHub/MooreaCoralFish_CS")
maxn <- read.csv("/Users/calliestephenson/Documents/GitHub/MooreaCoralFish_CS/data/MaxN.csv")
explan<- read.csv("data/explanatory_all_wide.csv")
```

### TIDY DATA:

First chunk of code subsets to only using 8 blocks per survey location, 4 from an 'on' and 4 from an 'adjacent'. I also remove pins where camera malfunctions made this not possible (Pin 13 and Pin 2).

```{r subset to 4 blocks per location}
block_count_per_location <- maxn %>%
  group_by(Pin, On.Adjacent) %>%
  summarise(num_blocks = n_distinct(Block))

set.seed(123)
subset_maxn <- maxn %>%
  filter(!(Pin == "13")) %>% 
  filter(!(Pin == "2")) %>% 
  group_by(Pin, On.Adjacent) %>%
  filter(Block %in% sample(unique(Block), 4, replace = FALSE)) %>%
  ungroup()

subset_block_count_per_location <- subset_maxn %>%
  group_by(Pin, On.Adjacent) %>%
  summarise(num_blocks = n_distinct(Block))

#Check that everybody has 4 blocks 2 times:
#table(subset_block_count_per_location$num_blocks, subset_block_count_per_location$Pin)
```

Since we could count some species as distinct individuals by life stages, I have combined those counts together here:

```{r combining life stages}
subset_maxn_combined_life_stages <- subset_maxn %>%
  group_by(Pin, On.Adjacent, Block, Species) %>%
  summarise(MaxN = if(n_distinct(Juvenile.Adult) > 1) sum(MaxN) else max(MaxN), .groups = 'drop') %>%
  arrange(Pin, On.Adjacent, Block, Species)
```

And built a little code to double check that it went correctly (should create two empty data frames)
```{r checking this}
# Summarize to find duplicates
resolved_duplicates <- subset_maxn_combined_life_stages %>%
  dplyr::group_by(Pin, On.Adjacent, Block, Species) %>%
  dplyr::summarise(count = dplyr::n(), .groups = 'drop') %>%
  dplyr::filter(count > 1)

# Subset the original data to only include the duplicates
resolved_duplicate_rows <- subset_maxn_combined_life_stages %>%
  dplyr::inner_join(resolved_duplicates, by = c("Pin", "On.Adjacent", "Block", "Species")) %>%
  dplyr::arrange(Pin, On.Adjacent, Block, Species)
```

I then deal with extreme schooling events following methods from the Donovan regimes paper: "Additional methodology was developed for dealing with outliers in the fish data, accounting for extreme observations of schooling species. Extreme observations in the database were defined by calculating the upper 99.9% of all individual observations (e.g. one species, size and count on an individual transect), resulting in 26 observations out of over 0.5 million, comprised of 11 species. The distribution of individual counts in the entire database for those 11 species was then used to identify observations that fell above the 99.0% quantile of counts for each species individually. These observations were adjusted to the 99.0% quantile for analysis."

```{r}
# Identify extreme observations I am using the 99% quantile instead because my data is smaller
extreme_threshold <- quantile(subset_maxn_combined_life_stages$MaxN, probs = 0.99) 

# Identify species that have extreme observations
extreme_species <- subset_maxn_combined_life_stages %>%
  filter(MaxN > extreme_threshold) %>%
  pull(Species) %>%
  unique()

#make function to adjust counts for these species:
adjust_counts <- function(df, species, quantile_threshold) {
  quantile_value <- quantile(df$MaxN[df$Species == species], probs = quantile_threshold, na.rm = TRUE)
 df$MaxN[df$Species == species & df$MaxN > quantile_value] <- quantile_value
  return(df)
}

#make the adjustment. I'm adjusting to the 90% quantile
for (sp in extreme_species) {
  adjusted_subset_maxn <- adjust_counts(subset_maxn_combined_life_stages, sp, 0.90)
}
```

and ending by renaming the dataframe as just fish_tidy for future use:
this allows me to make extra tidy data adjustments without breaking the dataframe name later on in the code!
```{r}
fish_tidy <- adjusted_subset_maxn
```

## Data Vis
Linda from Johanssen Lab reccommended to make a plot that is ordered by the most abundant fish near the seep and look for any patterns, so I went and made this plot a number of ways. First, I kept all the species and looked a just the average abundance at all pins, to see if the communities looked relatively similar in this way.

#### All species average abundance across gradient
```{r average maxn at each pin, fig.height= 10, fig.width=6}
maxn_avg <- fish_tidy %>%
  group_by(Pin, Species) %>%
  summarize(avg_MaxN = sum(MaxN, na.rm = TRUE) / 8)

maxn_avg %>%
  ggplot(aes(x = Species, y = avg_MaxN)) +
  geom_bar(stat = "identity", position = "dodge") +
  facet_wrap(~ Pin) +
  labs(y = "Average MaxN", x = "Block", title = "Average MaxN of Each Species Across Blocks by Pin") +
  coord_flip()+
  theme_minimal()
```

This is too busy to read, and no major patterns jump out. I subset this to just the top 20 species along the gradient, and again the order of the pins does not have biological relevance.

#### Most common 20 species average abundance across gradient
```{r same but only top 20 species, fig.height= 10, fig.width=6}
# Step 1: Calculate the overall average MaxN for each species
species_avg <- maxn_avg %>%
  group_by(Species) %>%
  summarize(overall_avg_MaxN = mean(avg_MaxN, na.rm = TRUE)) %>%
  arrange(desc(overall_avg_MaxN))

# Step 2: Identify the top 20 species based on the overall average MaxN
top_species <- species_avg %>%
  top_n(20, overall_avg_MaxN) %>%
  pull(Species)

maxn_avg_top <- maxn_avg %>%
  filter(Species %in% top_species)

maxn_avg_top %>%
  ggplot(aes(x = Species, y = avg_MaxN)) +
  geom_bar(stat = "identity", position = "dodge") +
  facet_wrap(~ Pin) +
  labs(y = "Average MaxN", x = "Block", title = "Average MaxN of Each Species Across Blocks by Pin") +
  coord_flip()+
  theme_minimal()
```

#### So, now I will order the pins by those most common at pin 14

```{r pin 14 most common, fig.height= 10, fig.width=6}
# Step 1: Create a new column for avg_MaxN at Pin 14
pin14_avg <- maxn_avg_top %>%
  filter(Pin == 14) %>%
  dplyr::select(Species, avg_MaxN) %>%
  rename(MaxN_Pin14 = avg_MaxN)

# Step 2: Add MaxN_Pin14 to the original dataframe and calculate overall average MaxN
maxn_avg_top <- maxn_avg_top %>%
  left_join(pin14_avg[,c("Species","MaxN_Pin14")], by = "Species") %>%
  group_by(Species) %>%
  mutate(overall_avg_MaxN = mean(avg_MaxN, na.rm = TRUE)) %>%
  ungroup()

# Step 3: Define species order based on MaxN_Pin14 and overall_avg_MaxN
species_order <- maxn_avg_top %>%
  # Replace NA in MaxN_Pin14 with a very low value to ensure they come last
  mutate(MaxN_Pin14 = ifelse(is.na(MaxN_Pin14), -Inf, MaxN_Pin14)) %>%
  arrange(desc(MaxN_Pin14), desc(overall_avg_MaxN)) %>%
  pull(Species) %>%
  unique()

# Step 4: Reorder species factor levels
maxn_avg_top <- maxn_avg_top %>%
  mutate(Species = factor(Species, levels = species_order))

# Step 5: Create the plot with the reordered species
p1 <- maxn_avg_top %>%
  ggplot(aes(x = Species, y = avg_MaxN)) +
  geom_bar(stat = "identity", position = "dodge") +
  facet_wrap(~ Pin) +
  labs(y = "Average MaxN", x = "Species", title = "Average Abundance of the Most Common 20 Species Across Sampling Locations") +
  coord_flip() +  # Flip coordinates to have species names on y-axis
  theme_linedraw()+ 
  theme(plot.title = element_text(size=9))

p1

#ggsave(filename = "output/most_common_fish.png", p1, height = 10, width = 5)
```

This isn't showing the most obvious patterns, but there were only a few species of fish that swam in the sane near the seep. So, I'll reorder the pins by the distance to the seep

#### Most common species average abundance at each pin by distance to seep:

```{r by dist to seep, fig.height= 10, fig.width=6}
explan <- explan %>%
  mutate(Pin = as.numeric(sub("V", "", CowTagID)))

maxn_explan <- left_join(maxn_avg_top, explan[,c("Pin", "dist_to_seep_m", "Low_Tide_Mean_Silicate_umolL")])

pin_order <- maxn_explan %>%
  distinct(Pin, dist_to_seep_m) %>%
  filter(Pin != 13) %>%  # Exclude Pin 13
  arrange(dist_to_seep_m) %>%
  pull(Pin)

maxn_explan <- maxn_explan %>%
  mutate(Pin = factor(Pin, levels = pin_order)) 

maxn_explan %>%
  ggplot(aes(x = Species, y = avg_MaxN)) +
  geom_bar(stat = "identity", position = "dodge") +
  facet_wrap(~ Pin) +
  labs(y = "Average MaxN", x = "Species", title = "Average Abundance of Each Species at Sampling Locations") +
  coord_flip()+
  theme_minimal()
```

To see if maybe a nutrient parameter would be good descriptor, I do this also by the low tide mean silicate

#### Most common species average abundance across the gradient of low tide mean silicate

```{r by dist to silicate, fig.height= 10, fig.width=6}
explan <- explan %>%
  mutate(Pin = as.numeric(sub("V", "", CowTagID)))

maxn_explan <- left_join(maxn_avg_top, explan[,c("Pin", "dist_to_seep_m", "Low_Tide_Mean_Silicate_umolL")])

pin_order <- maxn_explan %>%
  distinct(Pin, Low_Tide_Mean_Silicate_umolL) %>%
#  filter(Pin != 13) %>%  # Exclude Pin 13
  arrange(Low_Tide_Mean_Silicate_umolL) %>%
  pull(Pin)

maxn_explan <- maxn_explan %>%
  mutate(Pin = factor(Pin, levels = pin_order)) 

maxn_explan %>%
  ggplot(aes(x = Species, y = avg_MaxN)) +
  geom_bar(stat = "identity", position = "dodge") +
  facet_wrap(~ Pin) +
  labs(y = "Average MaxN", x = "Species", title = "Average Abundance of Each Species at Sampling Locations") +
  coord_flip()+
  theme_minimal()
```

#### Most common species average abundance across the gradient of nutrient delivery
Nutrient delivery quantified as a pc axis I got from the low tide mean of major nutrients across the gradient.This axis captures 72.87298% of the variation in mean low tide TA, Phosphate, Silicate, and N + N. Higer numbers on this axis indicate higher values of these variables.

```{r by pulse pc 1, fig.height= 10, fig.width=6}
explan <- explan %>%
  mutate(Pin = as.numeric(sub("V", "", CowTagID)))

maxn_explan <- left_join(maxn_avg_top, explan[,c("Pin", "pulse_pc1", "Low_Tide_Mean_Silicate_umolL")])

pin_order <- maxn_explan %>%
  distinct(Pin, pulse_pc1) %>%
#  filter(Pin != 13) %>%  # Exclude Pin 13
  arrange(pulse_pc1) %>%
  pull(Pin)

maxn_explan <- maxn_explan %>%
  mutate(Pin = factor(Pin, levels = pin_order)) 

maxn_explan %>%
  ggplot(aes(x = Species, y = avg_MaxN)) +
  geom_bar(stat = "identity", position = "dodge") +
  facet_wrap(~ Pin) +
  labs(y = "Average MaxN", x = "Species", title = "Average Abundance of Each Species at Sampling Locations") +
  coord_flip()+
  theme_minimal()
```

## Alpha Diversity:

#### Calculating richness against gradient metrics:

```{r}
species_richness <- fish_tidy %>%
  filter(!Pin == "13") %>% 
  filter(!Pin == "14") %>% 
  group_by(Pin, On.Adjacent, Block) %>%
  summarise(Richness = n_distinct(Species[MaxN > 0]))

species_richness_explan <- left_join(species_richness, explan[,c("Pin", "pulse_pc1", "Low_Tide_Mean_Silicate_umolL","dist_to_seep_m")])

species_richness_explan %>%
  ggplot(aes(x = Low_Tide_Mean_Silicate_umolL, y = Richness)) +
  geom_text(aes(label = Pin))+
  geom_point() +
  geom_smooth() +
  theme_minimal() +
  facet_wrap(~On.Adjacent)

species_richness_explan %>%
  ggplot(aes(x = pulse_pc1, y = Richness)) +
  geom_text(aes(label = Pin))+
  geom_point() +
  geom_smooth() +
  theme_minimal()+
  facet_wrap(~On.Adjacent)

species_richness_explan %>%
  ggplot(aes(x = dist_to_seep_m, y = Richness)) +
  geom_text(aes(label = Pin))+
  geom_point() +
  geom_smooth() +
  theme_minimal()+
  facet_wrap(~On.Adjacent)
```

#### Calculating diversity against gradient metrics:
```{r}
species_diversity <- fish_tidy %>%
  filter(!Pin == "13") %>% 
  filter(!Pin == "14") %>% 
  group_by(Pin, On.Adjacent, Block) %>%
  summarise(Diversity = diversity(MaxN, index = "shannon"))

species_diversity_explan <- left_join(species_diversity, explan[,c("Pin", "pulse_pc1", "Low_Tide_Mean_Silicate_umolL","dist_to_seep_m")])

species_diversity_explan %>%
  ggplot(aes(x = Low_Tide_Mean_Silicate_umolL, y = Diversity)) +
  geom_text(aes(label = Pin))+
  geom_point() +
  geom_smooth() +
  theme_minimal()+
  facet_wrap(~On.Adjacent)

species_diversity_explan %>%
  ggplot(aes(x = pulse_pc1, y = Diversity)) +
  geom_text(aes(label = Pin))+
  geom_point() +
  geom_smooth() +
  theme_minimal()+
  facet_wrap(~On.Adjacent)

species_diversity_explan %>%
  ggplot(aes(x = dist_to_seep_m, y = Diversity)) +
  geom_text(aes(label = Pin))+
  geom_point() +
  geom_smooth() +
  theme_minimal() +
  facet_wrap(~On.Adjacent)
```

## NMDS Non-Dimensional Ordination
Code from Linda:

```{r wide data}
# maxn_sum <- maxn %>%
#   group_by(Pin, On.Adjacent, Block, Species) %>%
#   summarize(MaxN = sum(MaxN, na.rm = TRUE)) %>%
#   ungroup()

#make it wide
wide_maxn_df <- pivot_wider(fish_tidy, 
                             id_cols = c("Pin", "On.Adjacent", "Block"),
                             names_from = Species, 
                             values_from = MaxN)

#but now with only the blocks we are using:
# 
# subset_maxn1 <- fish_tidy %>%
#   group_by(Pin, On.Adjacent, Block, Species) %>%
#   summarize(MaxN = sum(MaxN, na.rm = TRUE)) %>%
#   ungroup()
# 
# wide_maxn_df <- pivot_wider(subset_maxn1[,c("Pin","On.Adjacent","Block","Species","MaxN")], 
#                              id_cols = c("Pin", "On.Adjacent", "Block"),
#                              names_from = Species, 
#                              values_from = MaxN)

#make the NAs as 0's
wide_maxn_df <- wide_maxn_df %>% 
  mutate_all(~ifelse(is.na(.), 0, .))
```

```{r widen her up}
##make a dataframe with ONLY your fish data
##within the parentheses you write which columns this would be
Fish2 <-wide_maxn_df[c(4:90)]

##extract the info about location (in this case your habitats) from the dataset, this table needs to have equal number of rows as the fish table
Sites<-wide_maxn_df[c(1)]
#str(Sites)
```


I've been going back and forth on the transformation here, and am currently going with hellinger instead of vegan's default, the wisconsin. This is because, from my limited understanding, the hellinger better handles cases where species are not present in multiple sites (known as double zeros). 

```{r transform}
##hellinger transformation is a common transformation with community data when you have a lot of zeros
Fish_com <- decostand(Fish2, method = "hellinger" )

##constructing the dissimilarity matrix, using bray -curtis "how differently are they different"
mat.dis_fish <- vegdist(Fish_com,method="bray")
```

```{r}
set.seed(123)

nmds = metaMDS(mat.dis_fish,k=2, trymax=500, distance = "bray")
##stressplot is just a diagnostic for your data, shows how your datapoints are distributed and should be somewhat linear..
stressplot(nmds) 
nmds

##Stress Value = how well doe your NMDS represent reality (<0.2)
plot(nmds, type = "text")
plot(nmds)
```

```{r}
data.scores = as.data.frame(scores(nmds))
#including the factors 

data.scores$Site = Sites$Pin
#data.scores$Site <- factor(data.scores$Site, levels = c(1:223))

head(data.scores)
```

```{r}
data.spp.fit <- envfit(nmds, Fish2, permutations = 999)

head(data.spp.fit)

spp.scrs <- as.data.frame(scores(data.spp.fit, display = "vectors")) #save species intrinsic values into dataframe
spp.scrs <- cbind(spp.scrs, Species = rownames(spp.scrs)) #add species names to dataframe

head(spp.scrs)

sig.spp.scrs <- spp.scrs
#sig.spp.scrs <- subset(spp.scrs, pval<=0.05) #subset data to show species significant at 0.05

#head(sig.spp.scrs)
```

```{r}
##set theme!
mytheme3<-theme(axis.title = element_text(size = 12, colour = "black"), 
                panel.background = element_blank(), panel.border = element_rect(fill = NA, colour = "black"), 
                axis.ticks = element_blank(), axis.text = element_text(size = 12), legend.key = element_blank(), 
                legend.title = element_text(size = 12, colour = "black"), 
                legend.text = element_text(size = 12, colour = "black"))
```

```{r}
library(viridis)
gg2 <- ggplot(data = data.scores, aes(x = NMDS1, y = NMDS2))+ 
  scale_color_viridis(discrete = TRUE, option = "D")+
  scale_fill_viridis(discrete = TRUE)+
  labs(colour = "Site")+
 ggtitle("NMDS")+  mytheme3

data.scores$Site <- as.factor(data.scores$Site)

g2<-gg2+geom_point(data = data.scores, aes(colour = Site, shape = Site),size = 3, alpha = 0.8)+
  #geom_segment(aes(x = 0, y = 0, xend = NMDS1, yend = NMDS2), 
             #  data = spp.scrs)+
  ggrepel::geom_text_repel(data = spp.scrs, aes(x=NMDS1, y=NMDS2, label = Species), cex = 3, direction = "both", segment.size = 0.25) #add labels for species, use ggrepel::geom_text_repel so that labels do not overlap

g2 <- g2 + scale_shape_manual(values = 1:20)  # Assuming there are 20 unique sites

g2
```

```{r FOR MACKENZIE!!!}
g3 <- gg2+geom_point(data = data.scores, aes(colour = Site, shape = Site),size = 3, alpha = 0.8)+ scale_shape_manual(values = 1:20)
g3

#ggsave("NMDS_for_MT.png", g3)
```

```{r}
gg1 =ggplot(data = data.scores, aes(x = NMDS1, y = NMDS2))+ 
  scale_color_viridis(discrete = TRUE, option = "D")+
  scale_fill_viridis(discrete = TRUE)+
  labs(colour = "Reef.zone")+
  stat_ellipse(aes(fill = Site), geom = "polygon", alpha = .4,
               type="t",level = 0.95,linetype = 3)+ ggtitle("My NMDS")+  mytheme3


g1<- gg1+
  geom_point(data = data.scores, aes(shape = Site),size = 3, alpha = 0.8)+
  geom_segment(aes(x = 0, y = 0, xend = NMDS1, yend = NMDS2), 
               data = spp.scrs, size =0.5, alpha = 0.8, colour = "grey30")+
  scale_shape_manual(values = 1:20)+
  ggrepel::geom_text_repel(data = spp.scrs, aes(x=NMDS1, y=NMDS2, label = Species), cex = 3, direction = "both", segment.size = 0.25) #add labels for species, use ggrepel::geom_text_repel so that labels do not overlap

g1
```

```{r add species names in the data}
spp.scrs3 <- as.data.frame(scores(data.spp.fit, display = "vectors")) #save species intrinsic values into dataframe
spp.scrs3 <- cbind(spp.scrs3, Species = rownames(spp.scrs3)) #add species names to dataframe
spp.scrs3 <- cbind(spp.scrs3, pval = data.spp.fit$vectors$pvals) #add pvalues to dataframe so you can select species which are significant

#spp.scrs<- cbind(spp.scrs, abrev = abbreviate(spp.scrs$Species, minlength = 6)) #abbreviate species names
sig.spp.scrs3 <- subset(spp.scrs3, pval<=0.05) #subset data to show species significant at 0.05

sig.spp.scrs3
```
```{r set theme}
##set theme!
mytheme3<-theme(axis.title = element_text(size = 12, colour = "black"), 
                panel.background = element_blank(), panel.border = element_rect(fill = NA, colour = "black"), 
                axis.ticks = element_blank(), axis.text = element_text(size = 12), legend.key = element_blank(), 
                legend.title = element_text(size = 12, colour = "black"), 
                legend.text = element_text(size = 12, colour = "black"))
```

```{r add species names in the data to the plot}
options(ggrepel.max.overlaps = Inf)

gg2 = ggplot(data = data.scores, aes(x = NMDS1, y = NMDS2))+
  scale_color_viridis(discrete = TRUE, option = "D")+
  scale_fill_viridis(discrete = TRUE)+
  labs(colour = "Location")+
  stat_ellipse(aes(fill = Site), geom = "polygon", alpha = .15,
               type="t",level = 0.95,linetype = 3)+
  scale_shape_manual(values = 1:20)+
  mytheme3

g2<-gg2+geom_point(data = data.scores, aes(colour = Site, shape = Site),size = 3, alpha = 0.7)+
  geom_segment(aes(x = 0, y = 0, xend = NMDS1, yend = NMDS2),
               data = sig.spp.scrs3, size =0.5, alpha = 0.5, colour = "grey30")+
  ggrepel::geom_text_repel(data = sig.spp.scrs3, aes(x=NMDS1, y=NMDS2, label = Species), cex = 3, direction = "both", segment.size = 0.5, max.overlaps = 15) #add labels for species, use ggrepel::geom_text_repel so that labels do not overlap
g2

#ggsave("NMDS_sig_spp.png", g2, width=15, height=10)
```

```{r, fig.width=20, fig.height=20}
options(ggrepel.max.overlaps = Inf)

gg2 = ggplot(data = data.scores, aes(x = NMDS1, y = NMDS2))+
  scale_color_viridis(discrete = TRUE, option = "D")+
  scale_fill_viridis(discrete = TRUE)+
  labs(colour = "Location")+
  stat_ellipse(aes(fill = Site), geom = "polygon", alpha = .15,
               type="t",level = 0.95,linetype = 3)+
  scale_shape_manual(values = 1:20)+
  mytheme3

g2<-gg2+geom_point(data = data.scores, aes(colour = Site, shape = Site),size = 3, alpha = 0.7)+
  geom_segment(aes(x = 0, y = 0, xend = NMDS1, yend = NMDS2),
               data = sig.spp.scrs3, size =0.5, alpha = 0.5, colour = "grey30")+
  geom_text(data = sig.spp.scrs3, aes(x=NMDS1, y=NMDS2, label = Species), cex = 3, direction = "both", segment.size = 0.5, max.overlaps = 15) #add labels for species, use ggrepel::geom_text_repel so that labels do not overlap
g2

#ggsave("NMDS_with_sig_spp.png", g2, width = 20, height = 20)
```



# Constrained Ordination - Distance based redundancy analysis

I started with using the pulse pc axis, the low tide mean silicate, the distance to seep, and the distance to shore:

Tests revealed the shore distance didn't matter (permutation test p = 0.555), so I changed this to only use the pulse pc axis, the low tide mean silicate, the distance to seep, and the distance to shore:
```{r Distance based redundancy analysis}
# ##hellinger transformation is a common transformation with community data when you have a lot of zeros
Species_only <-wide_maxn_df[c(4:90)]
transformed_communities <- decostand(Species_only, method = "hellinger" )

# Extract the 'Pin' column from wide_maxn_df to merge with transformed data
Pin_column <- wide_maxn_df["Pin"]

# Combine the Pin column with the transformed species data
transformed_communities_with_pin <- cbind(Pin_column, transformed_communities)
transformed_communities_with_explan <- left_join(transformed_communities_with_pin, explan[,c("Pin", "Low_Tide_Mean_Phosphate_umolL", "Low_Tide_Mean_Silicate_umolL", "dist_to_seep_m", "Low_Tide_Mean_NN_umolL","Low_Tide_Mean_Ammonia_umolL")], by = join_by(Pin))
cap = capscale(transformed_communities ~ Low_Tide_Mean_Phosphate_umolL + Low_Tide_Mean_Silicate_umolL + dist_to_seep_m + Low_Tide_Mean_NN_umolL + Low_Tide_Mean_Ammonia_umolL, data = transformed_communities_with_explan, dist = "bray")
cap
```

The output reports the total inertia, which is the total amount of variation (dissimilarity) in the data. This inertia is decomposed into ‘constrained’ and ‘unconstrained’ components. The constrained component is the total amount of variation explained by the predictors (18.36%), while the unconstrained component is the remaining ‘residual’ variation. There is also info on ‘real’ and ‘imaginary’ components, due to the negative eigenvalues issue which arises with PCoA.


The default plot shows how these variables are loaded onto the first two CAP axes, and shows how the samples (circles) are ordinated on those axes, as well as the species scores (red crosses).
```{r}
plot(cap)
```

We can get the variance explained by these axes from summary:
```{r}
summary(cap)$cont
```

The first CAP axis explains 6.9% of the constrained community variation, and the second axis explains 4.3%. Therefore, this represents 2.07% of the total community variation. 

Though this is already pretty poor, I might as well finish it out as a coding exercise. The loading coefficients for the explanatory variables on the constrained axes are: 

```{r}
summary(cap)$biplot
```

To test the important of all the predictors in combination:
```{r}
anova(cap)
```

So this tests whether the total variation explained by the constrained axes is significant. Interestingly, though the amount of variation seems trivial, it is showing up as significant...

```{r}
anova(cap, by = "axis")
```
So, both the axes we have plotted are considered significant.

```{r}
anova(cap, by = "margin")
```

Interestingly, all the axes are coming up as significant contributors to this variation.

# PERMANOVA:
```{r}
PERMANOVA = adonis2(transformed_communities ~ Low_Tide_Mean_Phosphate_umolL + Low_Tide_Mean_Silicate_umolL + dist_to_seep_m + Low_Tide_Mean_NN_umolL + Low_Tide_Mean_Ammonia_umolL, data = transformed_communities_with_explan, dist = "bray", by = 'margin')

PERMANOVA
```

Again, all of our variables are significant contributors to community composition, though with very low r2.
